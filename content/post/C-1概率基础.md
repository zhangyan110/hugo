---
author: "张大仙儿"
date: 2019-10-01
title: "概率基本概念和相关计算"
tags: ["概率"]
categories: ["概率统计"]
---

## 事件及其概率

### 实验和事件：

- **一次实验**：对一个或者多个对象进行*一次*观察或测量的过程。
- **事件**：实验的结果。
- **随机实验**的特点：

1.  实验可以在相同条件下重复进行 ；
2. 每次实验的结果可能不止一个，但<u>实验的所有可能结果</u><u>（**基本事件**）</u>在实验之前是被确切知道的；
3. 在实验结束之前，不能确定该次实验的确切结果。          

​    具有上面三个特点的实验，为随机实验，相应的随机实验的结果称为**随机事件**。

​    举例：抛出一枚均匀的硬币，观察其出现正面或者反面的情况；

​                   掷一枚骰子，观察其出现的点数；

​                   从一批次品率为p的产品中随机抽出一个，观察其是正品还是次品。

- **样本空间和样本点**：在一项实验中，可以罗列出实验的所有可能结果（基本事件），把一项实验的基本事件的全体称为样本空间，而样本空间中每一个特定的实验结果称为样本点，是作为样本空间的组成元素。

###     概率：

- 概率是对于随机事件发生可能性大小的一种数值度量，数值上介于0到1之间，事件A发生的概率用p(A)表示。
- 从16世纪以来，共产生三种不同的概率定义：

1.  古典概率：p = 事件A中包含的基本事件 / 样本空间中基本事件总数   = m / n

2.  统计概率：p(A) = p 约等于 m/n

   是指历史上同类事件发生的稳定的频率。

   具体解释就是：若在同样条件下重复进行n次的实验中，事件A发生了m次，当实验次数n很大时，事件A发生的频率m/n就会稳定地在某一常数p上下波动，而且这种波动的幅度一定会伴随着实验次数的增加而不断减小，则定义常数p为事件A发生的概率。

3. 主观概率：区别于古典概率和统计概率都作为客观概率的性质，对于未来的某些事件，既不能通过客观的理论分析，也不能根据大量重复试验的概率来做估计，这时候支持决策的概率推断就是主观概率。

## 概率的性质和运算法则

### 1、概率的性质：

1. 非负性：对于任意事件 P(A) >= 0
2. 规范性： 0<= p(A) <= 1
3. 必然事件的概率等于1，不可能事件的概率等于0
4. 互斥事件的概率，若两个事件A和B互斥，则事件A发生或者事件B发生的概率，就等于这两个事件各自发生的概率之和。

### 2、互斥事件及其概率

- 在一项实验中，若两个事件中有一个发生，另一个就不可能发生，称这两个事件为互斥事件。从集合的角度理解就是，两个事件没有公共样本点。
- 两个事件互斥的情景也可以推广到多个事件：若事件A1、A2、........、An中，<u>任意两个</u> 事件互斥，则称这n 个事件为互斥事件。
- 互斥事件的概率加法规则：若两个事件A和B互斥，则事件A发生或者事件B发生的概率，就等于这两个事件各自发生的概率之和。即：p（AuB） = p(A) + p(B)

### 3、事件的补及其概率

- 在一项实验中，事件A为一个基本事件，则整个样本空间中除去事件A的剩下的就为A的补事件A-，也叫逆事件或对立事件。所以，A和A的对立事件不可能同时发生但必有一个发生。
- 可见，互逆事件首先是互斥事件,反之未必。
- 优定义知：p(A) + p(A-) = 1
- 在实际应用中，如果直接考察A事件比较复杂，可以通过其补事件来求A的概率问题。
- 明确一下互斥事件和对立事件的区别：

​         ![](http://graph.baidu.com/resource/1118b3431aca728b5c6d701571463414.jpg) 

​        图1中，事件A和事件B就是互斥事件，交集为空；图2中，事件A和事件B就是对立事件，两个事件构成整个    	    样本空间。

### 4、广义概率加法公式

- 对于任意两个事件A和B，广义加法公式可以表示为：p(AuB) = p(A) + p(B) -p(AB)。

### 5、条件概率与事件的独立性

- **条件概率**：已知事件B发生的条件下，求事件A发生的概率，称为已知B时A的条件概率，或称为给定B下A的概        				  率，记为p（A|B），文氏图如下：

​      ![](http://upload-images.jianshu.io/upload_images/2127249-4af1203ef9f2f691.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp) 

​    那么条件概率也就是求：如果B发生了，那这时候B的发生所会引起的A和B同时发生的概率是多少    

​    p(A|B) = p(AB) / p(B)

- **乘法公式**：由条件概率的公式可以得p(AB) = p(B)*p(A|B)

​                                                                                =P(A)*P(B|A)

​       这就是概率的乘法公式，可用于加法公式的求解中。

- **独立事件**：区别于条件概率中的事件A和事件B的相关性，独立事件A和B就是说，事件A和事件B的发生互不影响，也即满足：p(A|B) = P(A)      ;   P(B|A) = P(B)

​       这时候，对于两个相互独立的事件，乘法公式就变成：p(AB) = p(A)*P(B)

​      当然，两个独立事件的乘法公式可以推广到多个独立事件：若事件A1,A2,.........An相互独立

​      p(A1A2.....An) = p(A1)P(A2)......P(An)

## 全概率公式与贝叶斯公式

### 1、全概率公式：

- 条件概率和乘法公式对于概率理论及其应用的真正意义在于，它们能将一个相对复杂的事件分解成多个相对简单的便于计算概率的事件，而全概率公式正是这一思路的一般实现
- 全概率公式的应用场景：

​      ![](http://graph.baidu.com/resource/1114a3d3a98bcf9da54d501571459945.jpg) 

- 借助网上的一个文氏图的解释：

​     ![](http://upload-images.jianshu.io/upload_images/2127249-1c63915d1cb91d48.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

​    图中的总的样本空间S是由事件A和其对立事件A'共同构成的，即：p(A) + P(A') = 1

​    这个时候如果有个事件B，我们可以通过事件A来分两部分对事件B 进行解释：

​     ![](http://upload-images.jianshu.io/upload_images/2127249-4b27b8fe4bf7373a.jpg?imageMogr2/auto-orient/strip|imageView2/2/format/webp)   

​    如图，事件B就可以解释为和事件A重叠的一部分，以及和事件A‘ 重叠的另一部分，这样一来，事件B的概率就    	可以表示为：p(B) = p(BA) + P(BA')

​	由上面讲过的乘法公式 ，为了避免混乱我们用事件X和事件Y表示：p(XY) = p(X).P(Y|X)  =  P(Y).P(X|Y) 

​	就有：p(B) = P(A).P(B|A) + P(A').P(B|A')

- 当样本空间S是由更多的互不相容的事件A1,A2,A3 .....An组成的时候，全概率公式就有了最完全的形式：

​     ![](http://graph.baidu.com/resource/1116f6070bea40901e8f901571459394.jpg) 

​	概率论中，把满足上述条件的一组事件A1,A2,........An 称为完备事件组，由于它们的并恰好等于整个样本空间，	相互之间又无交叉，所以实际上它们是对样本空间的一个分割。

### 2、贝叶斯公式（逆概率公式）

- 概率论证明，由全概率公式可以推导得出另一个重要的公式叫逆概率公式。

​       ![](http://graph.baidu.com/resource/111e845739ff500014cdd01571462555.jpg)   这里呢，是将B1,B2,......Bn 作为完备事件组的，理解就可以。

- 应用场景：当我们通过全概率公式知道了一个事件会发生的概率，由于该事件的发生会存在不同的原因， 这时候，就可以通过逆概率公式，来计算各个原因导致该事件发生的概率，从而清楚哪些原因占比最重，哪些原因影响甚微。











---------下一节 随机变量及其概率分布.

